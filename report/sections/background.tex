\subsection{TCP}
The Transmission Control Protocol (TCP) is one of the core internet protocols.
It provides reliable, in-order delivery of data (a stream of bytes) between two
systems; it also offers a full-duplex service, meaning it allows a pair of byte
streams to flow, one in each direction, per connection. TCP is a packet-based
protocol, and uses positive acknowledgement of packets to signal successful
delivery. It also supports demultiplexing, which allows different application
processes on a host to share the underlying network, and flow and congestion
control which will be explained later in this section.

% Do we even need this paragraph?

TCP requires an explicit connection establishment phase called the ``three-way
handshake'' to establish common connection parameters between the two end hosts.
It also has a connection teardown phase which lets both parties free their
allocated resources. When the connection is set up, TCP buffers enough bytes
from the sending process to create a packet and sends it to the receiver. The
packet has many fields to make sure it reaches the correct destination such as,
sequence number which contains the first byte of data carried in the packet,
source/destination address, checksum to ensure correctness and many others.

As previously mentioned, TCP is a packet-based protocol, so after establishing
the connection between two communicating parties and creating the packets which
will be sent it will use flow and congestion control mechanisms to manage how
packets are exchanged throughout the network. Upon receiving packets, routers
and other devices in a network must assign some buffer space for these incoming
packets, in order to process them before forwarding along the path. Due to heavy
load or low outgoing link rate these buffers can become quite large resulting in
a queue; hence these routers become a bottleneck along the path. There is a risk
that the available buffer at the bottleneck may be filled if data is sent at a
faster rate than the device is able to forward or process it. This can result in
packets being dropped, and potentially the overload of the network. This is one
of the main problems which TCP must overcome, and the protocol implements flow
control and congestion control mechanisms to share bottlenecks fairly and avoid
overload.

Flow control is used to avoid sending data at a faster rate than the receiving
host is able to process. This is implemented using a sliding window algorithm
representing the amount of buffer space the receiver is able to commit to a
flow, and is advertised by the receiver using a field in each packet
acknowledgement sent. The sender may only keep one window of data in flight at
any given time, and so avoids overloading the receive buffer.

Congestion control is another rate-limiting mechanism which is used to avoid
overloading devices in the middle of the network path. Ideally, each TCP flow
will get an equal share of the capacity available at the bottleneck link. A TCP
flow must also detect congestion when the queues at the bottleneck are
overloaded, and back off its send rate accordingly.

The canonical congestion control algorithm is TCP New Reno. This algorithm
maintains a congestion window, similar to the receiver's flow control window,
which specifies the number of packets which may be in flight concurrently. The
sender must respect both the receive and congestion windows in determining an
appropriate send rate.

TCP New Reno flows begin in a slow start phase. An initial small congestion
window is chosen, and this is increased by one maximum segment size (MSS) for  % Explain MSS
each packet acknowledgment received. This has the effect of increasing the
congestion window size exponentially until a congestion event occurs; this can
either be a time out or three duplicate ACKs.

% Merge the following two paragraphs

The congestion event halves the congestion window and at this point TCP New Reno
exits the slow start phase and enters an additive-increase phase; where the
congestion window is increased by one MSS per round-trip time, which allows it
to expand into any additional capacity which becomes available as other flows
complete.

TCP New Reno implements two mechanisms for backing off when congestion is
detected. After a missed packet acknowledgement, the algorithm returns the
congestion window to its small initial size and continues in slow start.
Additionally, a fast recovery mechanism is used when temporary congestion
occurs. If three duplicate acknowledgements are received indicating a missed
packet, the congestion window is halved and additive-increase continues.

The repeated behaviour of probing for available capacity and then reducing the
window size when congestion occurs produces a distinctive saw-tooth of the
congestion window size.

% Explain RTT?

\subsection{WiFi and Interference}

% Add explanation of NIC

The 802.11 standards are a set of physical layer and MAC specifications for
implementing WiFi networks. 802.11 networks commonly operate on frequencies in
the 2.4 GHz and 5 GHz bands, which are divided into a number of overlapping
sub-bands more commonly known as channels. For example, the 802.11g channels in
the 2.4 GHz band are 22 MHz wide and spaced 5 MHz apart, beginning with 2.412
GHz. Given that the 2.4 GHz and 5 GHz bands are not specifically reserved for
WiFi, they are susceptible to noise as other devices such as microwave ovens and
bluetooth enabled electronics can interfere with the WiFi network. Furthermore,
a typical WiFi deployment would consist of several stations usually connected to
the network via an access point (AP). The greater the number of stations
connected to an AP on a channel, the higher the probability that the stations
would interfere with each other as they contend for the access to the medium in
order to transmit data. Interference as a results of other stations on the
network is undesirable as it leads to lower network utilization and hence lower
throughput.

In order to overcome interference with other stations transmitting on the same
channel, or a nearby channel, 802.11 implements carrier sense and random
back-off. Before transmitting, a station will sense the medium to determine if
another station is currently transmitting a data frame. If the medium is busy,
the station will defer for a random period of time and retry. This behaviour is
also used when multiple stations begin transmitting at the same time, and
collide. The random back-off selected by each station reduces the probability of
the stations interfering with each others transmission on the next retry and
this by extension ensures fairness.

The 802.11 MAC layer also implements packet acknowledgements separately from
TCP.\@ Acknowledgment packets are sent after each data frame is successfully
received. A station will generally retry transmitting a fixed number of times
without receiving acknowledgment before dropping a packet.

\subsection{Multipath TCP}

% Add the three goals of MPTCP

Devices with multiple network interfaces are common. Many consumer smart phones
have both WiFi and 3G interfaces, and data centres networks are often deployed
so that equipment racks are connected through multiple paths. Data centres
themselves are often multihomed to improve reliability, meaning that they have
several points of access to the wider internet. Multipath TCP is an
extension to TCP currently being standardised by the IETF, which aims to improve
redundancy and throughput by taking advantage of multiple paths for a single TCP
flow. In order to achieve this, Multipath TCP adds additional subflows to a TCP
connection such that the network interfaces of each host are connected in a
fully-connected mesh. % Explain fully connected mesh

% Maybe add why using multiple interfaces is a good idea?
% Reliability (load-balancing + failover)
% Throughput

Multipath TCP has introduced Coupled congestion control, which aims to behave
fairly when links are shared by other TCP or Multipath TCP flows. More
specifically, a single Multipath TCP flow should not gain more throughput than a
competing TCP flow simply because it has multiple subflows. However, the Coupled
algorithm also aims to utilise the available links fully when they would
otherwise be idle, meaning no other competing flows are sending.

The Coupled algorithm maintains a separate congestion window for each subflow
and uses the same congestion avoidance mechanisms as TCP New Reno, but links the
additive increase across all subflows to ensure fairness.

For each packet acknowledgment received on subflow $i$, the congestion window is
increased by

% Reference RFC here

\begin{align*}
  cwnd_i &= cwnd_i +
    \min\left(\frac{\alpha}{cwnd_\text{total}}, \frac{1}{cwnd_i}\right) \\
  \intertext{where}
  \alpha &=
    \frac{cwnd_\text{total} \cdot \max_i\left(\frac{cwnd_i}{rtt_i^2}\right)}
         {(\sum_i \frac{cwnd_i}{rtt_i})^2}
\end{align*}

Alpha is a parameter which controls how aggressive the MPTCP flow should be in
increasing its total send rate. Alpha is chosen such that the aggregate
throughput across all subflows is equal to the throughput a TCP New Reno flow
would gain on the best of the paths available. This ensures fairness with
competing TCP flows, where there may be a shared bottleneck at some point in the
network path. Additionally, the algorithm forces the congestion window of more
congested links to increase at a slower rate than less congested links. This has
the effect of shifting traffic  onto less congested paths, which helps to
balance traffic in a network.

If the available links are idle then the Coupled algorithm will allow each
subflow to use the full capacity available to it. For example, with two idle
links the aggregate throughput of an MPTCP flow will be the capacity of both
links combined.

% TODO: The following one and a half paragraphs are a draft of a "nicer"
% explanation of Coupled congestion control; of the intuition behind it in a
% sense

% This needs trimming and rewording

However, it is important to understand \textit{why} Coupled is expected to
eventually fill the link. In order to do that, one must understand how Coupled
tries to be fair in the first place. As the throughput of a Coupled flow
approaches the throughput a New Reno flow would get on the best link available
to the flow, Coupled gradually decreases the aggressiveness of each of its
subflows; this aggressiveness is controlled by the Alpha parameter (as
previously explained). It does this by effectively decreasing the growth rate of
each flow's congestion window which means that the flow will still continue to
try to use more and more of the link's capacity, but it will do so very slowly.
This means that should any other flow appear, its window will grow faster than
the Coupled flow's window, and when a congestion event occurs, the window size
of both the TCP flow and Multipath TCP flow will be halved the same way. This
phenomenon happens because the Coupled algorithm (Linked increases) does not
allow perfect resource pooling, in other words, it couples the increase rate of
all Multipath TCP subflows but keeps a separate congestion window for the
decrease, this measure ensures fairness by avoiding flappiness (which would be
seen if the algorithm was fully coupled). With perfect resource pooling the
traffic would go to the best path, but if there happened to be two paths with
the same level of congestion the traffic would enter a continuous state of
flapping between the two paths, leading to the congestion controller not
allocating any window time to other subflows (extremely unfair). By only
coupling the increase of subflows, limiting the increase rate to the maximum
increase a TCP flow would have, more window will proportionally be given to
lower loss rate subflows and the decrease will only depend on the congestion
window of each separate subflow which again will lead to Coupled being able to
probe the very lossy paths and finding the best paths more efficiently.  Due to
the Alpha parameter controlling the aggressivenes of Multipath TCP subflows and
the fact that their decrease behaves the same as New Reno this shows that the
aggregate throughput of all the subflows should only be up to the best a single
TCP flow would get on its best path. (maybe i'm stretching this a bit now or
repeating myself but hey my thought flow is not the greatest at this
time :D)  % TODO HERE

\subsection{Motivation}
Multipath TCP is without question a useful extension to vanilla TCP, but it was
primarily designed for wired networks in which links are usually independent.
The nature of wireless means that wireless interfaces can interfere with each
other, something Multipath TCP was not designed to deal with. Even networks on
different WiFi channels have been known to intefere, and so if Multipath TCP is
tries to use multiple interfaces at the same time, the self-interference might
prove sufficiently strong that the benefits of Multipath TCP are effectively
negated.

In this paper, we aim to investigate the extent to which wireless networks
interfere with each other, and how Multipath TCP behaves when it encounters
non-independent interfaces. To explore this, we will analyse its behaviour in a
series of wireless experiments. Our results are presented in the next section.
