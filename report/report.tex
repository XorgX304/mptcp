\documentclass[12pt,a4paper]{article}
\usepackage{authblk}
\usepackage{graphicx}
\usepackage[vmargin=3.5cm]{geometry}
\usepackage{hyperref}
\usepackage[lofdepth]{subfig}
\renewcommand{\arraystretch}{1.3}
\title{Cross-interface Interference and MultiPath TCP}
\author{Barlow-Bignell, J}
\author{de Silva, C}
\author{Gjengset, J}
\author{Oliha, P}
\affil{University College London}
\date{}
\begin{document}
\maketitle

\begin{abstract}
  ABSTRACT GOES HERE
\end{abstract}
\clearpage

\section{Introduction}

\section{Background}
\subsection{WiFi}
\subsection{Interference}
\subsection{TCP}
\subsection{MultiPath TCP}

\section{Methodology}
\subsection{Equipment}
\subsection{Experiment setups}
For most tested configurations, be it non-interfering 2.4 Ghz and 5 Ghz networks
or interfering 2.4 Ghz networks on the same channel, a fixed set of experiments
were run. The set consisted of the five tests outlined below:

\begin{enumerate}
  \item Network \#1 on machine \#1 only
  \item Network \#2 on machine \#2 only
  \item Network \#1 on machine \#1 and network \#2 on machine \#2 in parallel
  \item Network \#1 and \#2 on machine \#1
  \item Network \#1 and \#2 on machine \#2
\end{enumerate}

The two first tests were primarily used as baselines for the other tests to see
how well each network performed on its own without interference from the other
network. The parallel test was added to aid in measuring cross-interface
interference without MPTCP. This was necessary in order to measure how well
MultiPath TCP utilized the two networks compared to two entirely separate,
vanilla TCP clients. Originally we only ran one of the two final tests, but we
split it into two tests early on in order to be able to more directly compare
the utilization and performance of a network using MPTCP to its single and
parallel counterparts. Most of the comparisons done in this paper show
comparisons between test \#1, \#3 and \#4 or \#2, \#3 and \#5.
\subsection{Scripts}
In order to automate several oft-performed tasks such as running tests and
analyzing data, several scripts were developed and used throughout the writing
of this paper. The most interesting ones are outlined below.

Note that many of these scripts perform magic based on what wireless networks
the host machine is connected to. For this paper, two servers were used: fry and
zoidberg. Four wireless networks were set up, named bender-wifi, fry-wifi,
leela-wifi and zoidberg-wifi. Every test involved at least one of fry-wifi and
zoidberg-wifi, and the scripts below use the presence of a connection to one of
them as an indicator of which server will be used for tests.

\begin{description}
  \item[mp-start and mp-congestion]
    These two scripts enable MPTCP on the current machine, as well as set the
    appropriate congestion control algorithm on both the local machine and any
    remote machines it might be connected to.\ mp-start also stops any other
    wireless connections as well as some common network-intensive applications
    such as Dropbox. This prevents other traffic interfering with any running
    tests.
  \item[mp-routes]
    Examines the ip addresses of any active network interfaces and sets up
    routing tables according to
    \href{http://multipath-tcp.org/pmwiki.php/Users/ConfigureRouting}{http://multipath-tcp.org/\-pmwiki.php/\-Users/\-ConfigureRouting}.
  \item[mp-run]
    The primary testing script for MPTCP experiments. First, logs information
    about test location, connected networks, nearby wireless networks, tcp
    configuration parameters, kernel version, etc. Then it starts various
    logging daemons such as mp-stats and tcpdump to record state information
    during the experiments. It then runs netperf for a configurable period of
    time before it stops all logging daemons and compresses any large logs.

    Also supports doing downlink tests by spawning a local netperf server and
    running the netperf client on one of the server machines.
  \item[mp-stats]
    Collects the majority of statistics during a test. By default it samples
    data once every second. It logs stats from the wireless interfaces (signal
    strength, bitrate, retransmit failures), IP (bytes and packets sent) and TCP
    (queue sizes, rtt estimates, retransmits)
  \item[mp-int]
    Works much the same as mp-run, but instead of running TCP sessions with
    netperf on all connected interfaces, it runs a UDP\_STREAM test continuously
    on one interface and periodically on the other connected interace. This test
    is performed mainly to test the amount of interference between interfaces
    without the overhead of tcp.
  \item[mp-analyze]
    Given a test directory created by mp-run or mp-int, mp-analyze will extract
    information from various log files and output a simple space-separated file
    for each interface (and a total) with values for everything from throughput
    to bitrate to rtt. This information is then used by mp-plot, mp-stat or
    mp-cdf to display graphs or other statistical information about the data.
  \item[mp-plot]
    Given a test folder, will simply graph every statistic generated by
    mp-analyze for every interface the given test was run with. It also performs
    scaling to keep all values in a 0-100 range. Throughput is for example
    scaled to be shown in Mbps rather than Bps.
  \item[mp-stat]
    Given tuples of test folders and APs, will show confidence intervals for the
    corresponding interfaces in each test. Due to the variable throughput of
    WiFi, these results are not necessarily statistically significant, but they
    do provide a quick way of determining whether the results of two tests are
    somewhat related. Mostly replaced by mp-cdf.
  \item[mp-cdf]
    Given tuples of test folders and APs, will calculate the CDF for each
    corresponding interface in each test and graph them using gnuplot. The
    script uses the statistical programming language R to generate the CDF (or
    technically, the ECDF).
  \item[mp-show and mp-set]
    These two scripts are shortcuts to avoid having to type repeated folder/AP
    names or execute additional commands before running a script.\ mp-show
    simply calls mp-analyze and then mp-plot for a given folder.\ mp-set is
    slightly more advanced and tries to find all interfaces across tests
    connected to the same channel, and then plot each group of such interfaces
    using mp-cdf.
\end{description}
\subsection{Interrupt tests}

\section{Results and Evaluation}
Note that many of the graphs shown in this section are drawn using our
\texttt{mp-plot} script, which will scale values to keep them in the range
$[0,100]$. A couple of points about this scaling that are worth pointing out:
throughput is measured in Mbps; utilization is a measure of what percentage of
total throughput is sent through each interface and is displayed so that 80 is
0\% and 100 is 100\%.
\subsection{Cross-band interference} % 5 vs 2.4
\subsection{Cross-channel interference}
\subsection{Same-channel interference}
\subsection{Parallel vs. MPTCP performance}
\subsubsection{Fairness}
\subsection{MPTCP congestion control}
\subsection{Carrier Sense and cross-channel interference}
\begin{figure}[h]
 \centering
 \input{graphs/mp-int-2.4-ni.tex}
 \caption{Cross-channel interference}\label{graph:cc-interference}
\end{figure}

The cross-channel interference observed in Figure~\ref{graph:cc-interference} is
quite interesting as the throughput and utilization measurements show a
completely fair sharing between the two networks when both are active. There are
also nearly no 802.11 retransmit failures. This perfect split implies that
Carrier Sense is being employed here, effectively doing time multiplexing
between the interfaces.  This would be fine if the two networks were on the same
channel and should not transmit simultaneously, but the experiment shown in
Figure~\ref{graph:cc-interference} was performed with two networks on opposite
ends of the 2.4 Ghz spectrum (channel 1 and 11), and the two interfaces should
be able to both transmit at the same time, giving twice the throughput.

Looking at the total throughput, it is clear that some performance gain is
achieved, but clearly the gain is closer to 50\% than the 100\% one would expect
from non-interfering channels.

\begin{figure}[h]
 \centering
 \input{graphs/mp-int-2.4-i.tex}
 \caption{Same-channel interference}\label{graph:sc-interference}
\end{figure}

The results in Figure~\ref{graph:sc-interference} are perhaps even more
surprising as Carrier Sense should enforce a fairly strict time multiplexing
with two networks on the same channel, meaning the total throughput should
remain almost the same whether one or two interfaces are active. The
experimental results on the other hand show that the total throughput decreases
to almost 50\% when both interfaces are active. Clearly Carrier Sense is not
performing as it should.

\subsection{What if pigs could fly?} % Optimal solution

\section{Conclusion}

%Subfig example
%\begin{figure}[h]
% \centering
% \subfloat[][cross-channel interference] {\
%   \scalebox{0.55}{\input{graphs/mp-int-2.4-ni.tex}}\label{graph:cc-interference}
% }
% \subfloat[][same-channel interference] {\
%   \scalebox{0.55}{\input{graphs/mp-int-2.4-i.tex}}\label{graph:sc-interference}
% }
%
% \caption{Interference experiments}\label{graph:interference}
%\end{figure}

\end{document}
