\documentclass[12pt,a4paper]{article}
\usepackage{authblk}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{xfrac}
\usepackage[vmargin=3.5cm]{geometry}
\usepackage{hyperref}
\usepackage[lofdepth]{subfig}
\renewcommand{\arraystretch}{1.3}
\title{Cross-interface Interference and MultiPath TCP}
\author{Barlow-Bignell, J}
\author{de Silva, C}
\author{Gjengset, J}
\author{Oliha, P}
\affil{University College London}
\date{}
\begin{document}
\maketitle

\begin{abstract}
  ABSTRACT GOES HERE
\end{abstract}
\clearpage

\section{Introduction}
With the extension of Multipath TCP to regular TCP it is possible to have
multiple simultaneous connections on one device. On modern mobile devices that
usually have more than one network interface(wifi, 3G) this can gaurantee extra
reliablity making the connections more robust to loss. With the promise of
greater throughput and reliability, it is immediately easy to see usage
scenarios that involve  multiple wifi cards on a laptop in order to benifit from
MPTCP.

Interference is a bane of any wireless network and wifi is no exception to this.
Multiple devices with single wifi card often interfer with each other and rely
on 802.11 carrier-sense to ensure fair access to the wireless medium. Hence it
is only natural that multiple wifi cards on a device would lead to some degree
of interference.

The goal of this report is to investigate the degree of interference(if any)
between multiple wifi interfaces on the same device, how this interference
influences throughput and fairness to other devices on the network, and how this
influences the multipath TCP protocol. The remaining part of this report would
present a brief background on TCP, Wifi, and Multipath TCP, the methodology of
the experiments conducted, results and evaluation of these experiments and the
conclusions reached.

\section{Background}
\subsection{WiFi}
\subsection{Interference}
\subsection{TCP}
\subsection{MultiPath TCP}

\section{Methodology}
\subsection{Equipment}
The tools used to create the test environment includes four 2.4GHz Wifi USB
dongles, a 5GHz Wifi USB dongle, three wireless basestations; two operating on
the 2.4GHz channel and one dual-band on 2.4GHz and  5GHz channel, two server
machines and two laptop PCs. At the time of this experiment, both the servers
and personal computers were running the most current version of the Linux MPTCP
enabled kernel gotten from \href{http://multipath-tcp.org/}{multipath-tcp.org}

\subsection{Experiment setups}
For most tested configurations, be it non-interfering 2.4 Ghz and 5 Ghz networks
or interfering 2.4 Ghz networks on the same channel, one of two tests setups
were used. The first setup was running the five tests outlined below
sequentially:

\begin{enumerate}
  \item Network \#1 on machine \#1 only
  \item Network \#2 on machine \#2 only
  \item Network \#1 on machine \#1 and network \#2 on machine \#2 in parallel
  \item Network \#1 and \#2 on machine \#1
  \item Network \#1 and \#2 on machine \#2
\end{enumerate}

The two first tests were primarily used as baselines for the other tests to see
how well each network performed on its own without interference from the other
network. The parallel test was added to aid in measuring cross-interface
interference without MPTCP.\@ This was necessary in order to measure how well
MultiPath TCP utilized the two networks compared to two entirely separate,
vanilla TCP clients. Originally we only ran one of the two final tests, but we
split it into two tests early on in order to be able to more directly compare
the utilization and performance of a network using MPTCP to its single and
parallel counterparts. Most of the comparisons done in this paper show
comparisons between test \#1, \#3 and \#4 or \#2, \#3 and \#5.

The other common test setup was using three machines at the same time so that
one machine was connected to network \#1, one machine to network \#2, and one
machine to both networks. All machines were running the MPTCP kernel. This setup
allowed us to more directly compare the performance of MPTCP to that of a two
simultaneous non-MPTCP clients. It also let us evaluate the fairness of MPTCP
when other clients are also using the network.

\subsection{Scripts}
In order to automate several oft-performed tasks such as running tests and
analyzing data, several scripts were developed and used throughout the writing
of this paper. The most interesting ones are outlined below.

Note that many of these scripts perform magic based on what wireless networks
the host machine is connected to. For this paper, two servers were used: fry and
zoidberg. Four wireless networks were set up, named bender-wifi, fry-wifi,
leela-wifi and zoidberg-wifi. Every test involved at least one of fry-wifi and
zoidberg-wifi, and the scripts below use the presence of a connection to one of
them as an indicator of which server will be used for tests.

\begin{description}
  \item[mp-start and mp-congestion]
    These two scripts enable MPTCP on the current machine, as well as set the
    appropriate congestion control algorithm on both the local machine and any
    remote machines it might be connected to.\ mp-start also stops any other
    wireless connections as well as some common network-intensive applications
    such as Dropbox. This prevents other traffic interfering with any running
    tests.
  \item[mp-routes]
    Examines the ip addresses of any active network interfaces and sets up
    routing tables according to
    \href{http://multipath-tcp.org/pmwiki.php/Users/ConfigureRouting}{http://multipath-tcp.org/\-pmwiki.php/\-Users/\-ConfigureRouting}.
  \item[mp-run]
    The primary testing script for MPTCP experiments. First, logs information
    about test location, connected networks, nearby wireless networks, tcp
    configuration parameters, kernel version, etc. Then it starts various
    logging daemons such as mp-stats and tcpdump to record state information
    during the experiments. It then runs netperf for a configurable period of
    time before it stops all logging daemons and compresses any large logs.

    Also supports doing downlink tests by spawning a local netperf server and
    running the netperf client on one of the server machines.
  \item[mp-stats]
    Collects the majority of statistics during a test. By default it samples
    data once every second. It logs stats from the wireless interfaces (signal
    strength, bitrate, retransmit failures), IP (bytes and packets sent) and TCP
    (queue sizes, rtt estimates, retransmits)
  \item[mp-int]
    Works much the same as mp-run, but instead of running TCP sessions with
    netperf on all connected interfaces, it runs a UDP\_STREAM test continuously
    on one interface and periodically on the other connected interace. This test
    is performed mainly to test the amount of interference between interfaces
    without the overhead of tcp.
  \item[mp-analyze]
    Given a test directory created by mp-run or mp-int, mp-analyze will extract
    information from various log files and output a simple space-separated file
    for each interface (and a total) with values for everything from throughput
    to bitrate to rtt. This information is then used by mp-plot or mp-cdf to
    display graphs or other statistical information about the data.
  \item[mp-plot]
    Given a test folder, will simply graph every statistic generated by
    mp-analyze for every interface the given test was run with. It also performs
    scaling to keep all values in a 0-100 range. Throughput is for example
    scaled to be shown in Mbps rather than Bps.
  \item[mp-cdf]
    Given tuples of test folders and APs, will calculate the CDF for each
    corresponding interface in each test and graph them using gnuplot. The
    script uses the statistical programming language R to generate the CDF (or
    technically, the ECDF).
  \item[mp-set]
    This script is a shortcut to avoid having to type repeated folder/AP
    names to plot certain data sets. It tries to find all interfaces across
    tests connected to the same channel, and then plot each group of such
    interfaces using mp-cdf.
  \item[mp-merge]
    Merges the data from several test sets into a single set. Optionally also
    does a simple form of normalization in order to make the results more
    relevant when the merged set of samples are plotted as a single CDF.\@ The
    normalization is performed by finding the average of the median throughput
    in each test in the set, and then subtracting that from every throughput
    measurement. This retains both the shape and width of the CDFs, while
    ignoring the absolute throughput values which can vary quite a lot from one
    test to another due to other clients using the network.
  \item[mp-gather]
    Simple wrapper around mp-merge that takes folders of test sets as arguments,
    extracts ap names and calls mp-merge for all related tests. For example, it
    will find all same-channel, coupled test sets in all its arguments, and
    merge them, optionally using mp-merge's normalization feature.
\end{description}
\subsection{Interrupt tests}
For the interrupt tests, each wireless interface is connected to a separate
basestation just like in the other setups, the only difference here is that one
of the interfaces alternates between being in idle and active mode while the
other interface is always active. The alternating interface is idle or active
for fixed time slots in the duration of the experiment.

The idea behind alternating the active periods for one of the interfaces is
simple; ideally if there is no interference between these interfaces then there
would not be a loss in throughput for the always-active interface when the
alternating interface is active. Given the nature of wireless signals this is a
rather utopic idea, hence a more desirable result would be one that shows
minimal drop in throughput. Minimal in this scenario means that each interface
should achieve at least 90\% of its throughput in a single interface setup.
However, the graph of figure FIG shows that ther is some considerable drop in  % TODO: insert correct figure reference
throughput when the alternating interface is switched-on thereby indicating the
presence on non-minimal cross-interface interference between the wireless
interfaces.

\section{Results and Evaluation}
Note that many of the graphs shown in this section are drawn using our
\texttt{mp-plot} script, which will scale values to keep them in the range
$[0,100]$. A couple of points about this scaling that are worth pointing out:
throughput is measured in Mbps; utilization is a measure of what percentage of
total throughput is sent through each interface and is displayed so that 80 is
0\% and 100 is 100\%.

\subsection{Using multiple interfaces}
One of the advantages of using MPTCP is the fact that multiple interfaces can be
used which makes the network faster, more reliable and less prone to congestion
(at least in theory; as multiple subflows are used to split the load). However
before we jump straight into MPTCP there are a few questions about using
multiple interfaces worth asking:

\begin{enumerate}
  \item Does it make sense to use 2 interfaces at the same time? (when compared
    to a single interface)
  \item Is there ever a penalty to using them?
  \item Is there any performance gain?
\end{enumerate}

To answer these questions several experiments where ran using different setups
(as can be seen in the setup section). Most of the results obtained in both
interfering and non-interfering experiments between 5-2.4 and 2.4-2.4 show that
the 2 interfaces always have better throughput than the single interface; this
can be seen more clearly in the CDF graphs (parallel vs single graphs - look for
appropriate graphs!!!).

% Maybe display a few graphs showing this examples of 5-2.4 and 2.4-2.4 both i
% and ni

The results obtained from these graphs also answer the second and third
questions. It is clear that these results show that there is no penalty to
having multiple interfaces (unless these interfere with each other and the
combined throughput is worse, which is not the case) because carrier sense will
make sure that the total throughput is not increased even if both interfaces are
on the same channel; the performance gain is quite significant as shown in the
results, the combined throughput for the 2 interfaces is much better than the
single. (should also mention that this would work assuming the congestion
control mechanism gives you a fair share of capacity (?))

Based on this it is safe to say that using multiple interfaces is advantageous
which also implies that MPTCP is in fact a good idea, bringing us to the next
section.

\subsection{Multiple interfaces and MPTCP}

In the previous section it was shown that multiple interfaces are better than a
single one, but what exactly does MPTCP do with multiple interfaces? The
question that should be asked now is how does MPTCP work with multiple
interfaces and how much better does it behave when compared against parallel
experiments.

As stated in the previous section a lot of experiments were run in order to
observe how MPTCP behaves, it was decided that the results from the MPTCP
experiments should be compared against the parallel ones as they are the
benchmark of how well the network can behave. To make the results more
conclusive and accurate different congestion control mechanisms were used (reno
and coupled).

Different sets of experiments were run in a span of several days using the same
setup. During the first few days all the experiments were run during 10 minutes
using the coupled congestion-control, 5 minutes for the upstream and 5 minutes
for the downstream. However, after observing some unusual results between the up
and down tests, where the down tests would in general be fairer at distributing
the load because they could see loss and correctly adjust the cwnd, it was
decided that the lenght of the experiments would be increased to 15 minutes
each. Later on experiments using the reno congestion-control were also run in
order to compare results against experiments using coupled. After a couple of
weeks running this setup, the lenght of the experiments was changed to 2 minutes
and 3 different machines would run in simultaneous using both reno and coupled.

% Note that towards the end we were merging results across multiple tests and
% looking at the CDFs for these aggregated tests

\subsubsection{Upstream and Downstream}
% TODO: Correct figure refernces here
In the start both upstream and downstream experiments were run, but after
several rounds it became clear that the downstream experiments were very similar
and regular showing a fair distribution (throughput and utilization) between
both networks and a fairly constant RTT as can be seen in
\texttt{2013-07-18/ni-2.4-pete-down} and
\texttt{2013-07-18/ci-fry-2.4x2-ni-down} (which did not prove the same for
upstream \texttt{2013-07-18/ni-2.4-pete-up},
\texttt{2013-07-18/ci-fry-2.4x2-ni-up}). In spite of that it was decided at the
time that upstream only experiments were to be run more extensively. It was
later discovered that due to the sender not seeing loss, the cwnd would grow
aggressively and the tests behave in such an unfair way (as will be explained
later in the report). When the setup was changed to run the simultaneous
experiments more rounds of downstream experiments were run to support our
findings.

\subsubsection{5 \& 2.4 interference}
% TODO: Correct figure refernces here
Most of the experiments between 5GHz and 2.4GHz showed that there is little
interference between them. The 5GHz network behaves as expected, showing high
throughputs with an average of 24 - 25 Mbps  for both the single and the
parallel experiments, even when exposed to interference from other Wi-Fi sources
apart from the 2.4Ghz network (when there were people around the floor on their
cellphones and on skype) the throughput remained roughly the same, althought the
RTT varied significantly especially in the single test as can be seen in
\texttt{19-07-13/parallel-5-up} and \texttt{19-07-13/single-2.4-up} (which also
reflected in the send queue).

The 2.4Ghz network as mentioned before is also not highly affected by
interference from the 5GHz network. It behaved similarly for both the single and
parallel tests with little difference between throughputs, averaging at 16 Mbps
for single and around 13 Mbps for parallel (so a slight drop in throughput); but
it should be pointed that it is more susceptible to outside interference. Even
so as can be see in \texttt{19-07-13/single-2.4-up} and
\texttt{19-07-13/parallel-2.4-up} both the throughputs and RTTs (with a few
spikes for single) behave similarly, also the send queue is kept fuller at the
single experiment (better throughput).

The mptcp graphs correlates the results described above as can be seen in
\texttt{19-07-13/mptcp@2.4-up}.

The parallel graphs against MPTCP correlate what has been described above.

\subsubsection{2.4 cross-channel interference}
Tests between cross-channel (different channels) 2.4 networks showed that there
is quite a lot of interference between them even though they are in different
channels (usually 1/5 or 1/11). This was quite surprising as it was expected
that by having each network in different channels interference would be kept to
a minimum. There could be different reasons for this such as the APs not having
strong enough antennas (more likely to be susceptible to interference) or the
fact the APs might be positioned very close to each other which could cause
self-interference.

% TODO: Correct figure refernces here
As can be seen in \texttt{02-08-13/mptcp@1a-up} and
\texttt{01-08-13/mptcp@11-up} (i/ni mptcp experiments) the throughput in
\texttt{mptcp@1a-up} is close to the one in \texttt{01-08-13/mptcp@11-up}, but
significantly worse in one of the links; however the other link is very similar
which is quite surprising. The throughputs average around 20 Mbps for for ni and
15 for i. So even if so slightly the ni experiments are performing quite close
to the interfering ones which should not happen in theory. Experiments with the
APs positioned far apart showed a much fairer distribution between the 2
networks as usually the network in the less busy channel dominates the
throughput.

The comparison between the ni mptcp against the parallel graph, showed that
MPTCP is underperforming (?) as the aggregate throughput of the MPTCP flows does
not amount to the best single path; this can be seen in the cdf graph
\texttt{01-08-13/coupled-1} which uses the coupled congestion control.

For reno, the results (as expected) are slightly better, but the graph should
show all the lines on top of each other which is not the case as can be seen in
\texttt{01-08-13/reno-1} (even though the aggregate throughput of MPTCP is
roughly the same as the best single path).

\subsubsection{2.4 same-channel interference}
% TODO: Correct figure refernces here
As expected tests using the same channel showed a lot of interference, usually
with one of the networks being favoured over the other (one network would have a
quite high throughput around 15 Mbps while the other would have a very low one
around 6 Mbps). This could be due to the fact that the coupled congestion
control favours the less lossy link so it sends more traffic through that link
and barely any through to the other (This could be seen when the graphs were
compared to the single tests, in which separately each network performed
similarly but when run simultaneously or in parallel one of the networks was
always favoured) as in \texttt{02-08-13/mptcp@1a-up}. When the
congestion-control was switched to Reno it was apparent right away that the
distribution between the links was much fairer and better distributed. This
happens because reno unlike coupled runs congestion control separately for each
interface so it will try to fully utilise both networks resulting in a fairer
distribution as can be seen in \texttt{02-08-13/mptcp@1b-up}. Coupled as
mentioned before avoids lossy links so it will avoid loading that link with
traffic and only using it as backup for when the better link is full.

Reno might be more appropriate for networks on different channels as it will not
avoid lossy links but try to equally share the load between the 2 channels
despite of how lossy the links are. This would be fairer to both networks as
both get to send without one being favoured over the other.

The CDF graph for MPTCP using coupled and parallel show that MPTCP is
outperforming the best single path which should not happen (as the aggregate
throughput should be the same as the best path not more - it's violating rule 2:
do no harm); this means that MPTCP is getting more than its fair share of
throughput.

The same CDF but running reno behaves as expected with most of the lines on top
of each other (a fair distribution) except one of the MPTCP lines which is doing
slighlty worse than the rest.

\subsection{Fairness}
As previously mentioned most of the final experiments were run simultaneously
between 3 PCs (2 running parallel and 1 MPTCP) and the results of these were
quite interesting. Most of the graphs showed MPTCP performing as well as
parallel (choose appropriate graphs) but they also showed that MPTCP was not
being fair as it was using up more than its fair amount of share at the cost of
other clients, in other words it violated rule number 2 of the coupled
congestion control (do not harm). After seeing similar results for several tests
it was noted that the congestion window was growing quite aggressively which led
to much debate and investigation. Afterwards it was found that the reason the
cwnd was growing so aggressively was that the sender was not seeing any loss
(hence the agressive growth). This was caused by the local queue at the sender,
as it was later found, the IP queue is very large (128KB) so it keeps receiving
packets and keeps the queue full at all times, never overflowing and never
causing loss; even when packets are sent to the socket buffer the ip queue
simply takes more packets to replace those it sent. This is not ideal for MPTCP,
the queue is always full and sending, the cwnd keeps growing and the alpha
variable cannot cap the growth because it sees no loss, so in conclusion MPTCP
does not work correctly (the cwnd size is not correct).

Different solutions to this problem have been considered, the most relevant ones
being: reducing the number of retries, TSQ, calculating the RTT variance every
ack (instead of every RTT) and Master socket/MPTCP socket)

\subsection{Downlink experiments}
The setup for this test is the same as explained in the setup 3 of "Testing
Setups". Here the goal of the experiment is to analyse MPTCP's behaviour with
regards to interference, throughput and fairness to other TCP flows on the
downlink. For this experiment 2 AP's are used; one on 5GHz frequency band and
the other on 2.4GHz. To ensure that the AP's have the same amount of load, each
parallel machine connects to one AP while the MPTCP machine connects to both AP
using one of its interface for each; thereby making it seem as if each AP is
connected to 2 clients. This also applies to the two servers to which the TCP
connections would be made. Netperf is used to create downlink traffic between
the servers and client; this lasts for two minutes time slots. This is ran
multiple times and the aggregate result can be seen in figure FIG.             % TODO: correct fig (maybe graphs from 14-08-2013).

The coupled congestion control algorithm is used by all machines in this test.
For the parallel machines this is has no consequence since they only have one
TCP flow each so in essence it acts like the normal TCP congestion algorithm.
However for the MPTCP flows, coupled congestion control limits the aggregate
throughput to be as good as the throughput of the best link on that path. In
order words, the sum of the throughput should be the same as that of the single
5GHz channel. We do actually see this phenomenon from the graphs where the sum
of the MPTCP throughputs is about the same as that of the best parallel link
save for some slight variation which can be attributed to the wireless
environment in which these experiments where carried out.

From the graph we see MPTCP also tries to achieve a form of load balancing by
moving data off the congested path in this case the 2.5GHz link onto the 5GHz
link.

It should be noted that this also shows that MPTCP running the coupled
congestion control algorithm ensures fairness on the downlink. It does this with
the aid of loss feedback from the channel; so as packets build up in the AP, the
queue fills up leading to packet drops and then loss. This indicates to the
MPTCP sender to slow down the rate.

\subsection{Parallel vs. MPTCP performance}
\subsubsection{Fairness}
\subsection{MPTCP congestion control}
\subsection{Carrier Sense and cross-channel interference}
\begin{figure}[h]
 \centering
 \input{graphs/mp-int-2.4-ni.tex}
 \caption{Cross-channel interference}\label{graph:cc-interference}
\end{figure}

The cross-channel interference observed in Figure~\ref{graph:cc-interference} is
quite interesting as the throughput and utilization measurements show a
completely fair sharing between the two networks when both are active. There are
also nearly no 802.11 retransmit failures. This perfect split implies that
Carrier Sense is being employed here, effectively doing time multiplexing
between the interfaces.  This would be fine if the two networks were on the same
channel and should not transmit simultaneously, but the experiment shown in
Figure~\ref{graph:cc-interference} was performed with two networks on opposite
ends of the 2.4 Ghz spectrum (channel 1 and 11), and the two interfaces should
be able to both transmit at the same time, giving twice the throughput.

Looking at the total throughput, it is clear that some performance gain is
achieved, but clearly the gain is closer to 50\% than the 100\% one would expect
from non-interfering channels.

\begin{figure}[h]
 \centering
 \input{graphs/mp-int-2.4-i.tex}
 \caption{Same-channel interference}\label{graph:sc-interference}
\end{figure}

The results in Figure~\ref{graph:sc-interference} are perhaps even more
surprising as Carrier Sense should enforce a fairly strict time multiplexing
with two networks on the same channel, meaning the total throughput should
remain almost the same whether one or two interfaces are active. The
experimental results on the other hand show that the total throughput decreases
to almost 50\% when both interfaces are active. Clearly Carrier Sense is not
performing as it should.

\subsection{Observations on data oddities}
Throughout our experiments, we have come across several rather odd results,
correlations and trends that we could not immediately explain. Some of these
turned out to be glitches, but many made complete sense after some hard
thinking. This section aims to explain most of the oddities that can be observed
in some of the graphs given above.

\subsubsection{Congestion window and the send queue}
Most of the time plots above show the send queue size hugging the congestion
window size through the entire test. Since we were seeing so little loss in many
of our tests, and thus the congestion window was clearly growing larger than it
should be, we did not find this strange at all, since most of the bytes
of the congestion window was bound to be in the host's send queue. Given this
assumption, we would expect the send queue to be closely following the
congestion window, with a small gap between them to cater for any packets in
flight.

After a while, however, we noticed that we were seeing the send queue following
the congestion window also when we \textbf{were} seeing loss and the congestion
window was \textbf{not} inflated. In these cases, there should not be many
packets in the send queue at all; they should mostly all be in flight.

Our first guess was that the send queue size included the TCP socket buffer
size, but this was quickly discarded as the TCP socket buffer should be close to
full (i.e.\ a constant value) the entire time thanks to netperf adding packets
in tight loop. That was clearly not what was happening here.

It turns out that the reason for this is surprisingly simple; the send queue
size reported by the kernel includes \textit{unacked packets}. TCP keeps these
around because it might have to resend them, so until they have been ACKed, they
will continue to take up space in the queue. This explains both why we were not
seeing a gap between the send queue size and the congestion window in the
no-loss experiments, \textbf{and} why the send queue was seemingly following the
congestion window when loss was occurring.

\subsubsection{Inflated RTT}
Many of our results show very high RTTs despite the network being relatively
fast (i.e.\ we see an RTT of $\approx 7$ms with \texttt{ping}). In fact, the
RTTs are so high that they are plotted as 10s of ms in the plots to fit them in
the range $[0-100]$.

The smoking gun here is that the RTT seems to increase and decrease with the
size of the send queue. As observed in section SOMETHING, the lack of loss     % TODO: set correct section reference
causes an unbounded growth of the congestion window, but with most of the
packets stuck in the send queue. Since TCP estimates RTT based on when the
packet was put into the send queue, \textbf{not} when it is actually send by the
NIC, the RTT estimate will include the time a packet spent in the queue. Since
the queue is growing, so will the RTT.

\subsubsection{Logarithmic growth of congestion window}
When looking at the growth of the congestion window, it is clear that it shows
something resembling logarithmic growth rather than the familiar linear
sawtooth. To understand why this is happening, it is necessary to look closer at
how the congestion window is increased.

The new reno congestion control used by MPTCP tries to increase the congestion
window by one MSS per RTT.\@ It does this by increasing the congestion window by
$\sfrac{1}{cwnd}$ per received ACK.\@ This works well when the assumption that
increasing the congestion window will cause you to send more packets, and thus
receive more ACKs per RTT, but falls apart when the link layer masks loss.

What happens when TCP does not see loss, as discussed in section SECTION, is   % TODO: set correction section reference
that the congestion window is usually larger than what the NIC can handle
already, and so increasing it will not cause any more packets to be sent, and
thus the number of ACKs received in an RTT will remain constant. The
$\sfrac{1}{cwnd}$ term on the other hand will grow smaller, and thus the growth
of the congestion window relative to the congestion window size per RTT will
decrease, leading to the logartichmic growth we see.

\subsubsection{Congestion window and throughput}
In figure 2013-08-14/100+100/parallel we can observe another very strange      % TODO: insert correct figure reference here
phenomenon that occured in a number of experiments. Here, we see a curious
correlation between throughput and the congestion window size. Other tests also
show a correlation between then two, but it is particularly evident in this one
as the throughput looks like it is actually bounded by the congestion window.
This struck us as very odd since the congestion window is plotted in 10s of
kilobytes, whereas the throughput is plotted in Mbits.

To determine why this was happening, we first tried to find commonalities
between the graphs that were showing this peculiar trend. It turns out that we
were only seeing this in tests we had a high RTT with constant loss rates or
high amounts of loss. These cases both share the feature that the congestion
window is constrained from growing to the full bandwidth delay product of the
link, and thus no queues are expected to build up anywhere in the network. The
limiting factor for the throughput is the congestion window not allowing TCP to
put more packets into the send queue, even though the link is ready to send. The
net effect of this is that the throughput is limited by the congestion window;
whenever the congestion window grows, the throughput increases because TCP is
allowed to put more packets on the wire. If the congestion window is halved, TCP
stops sending packets pretty much immediately, and the throughput drops.

This still did not explain why we were seeing close to a 1:1 correspondence
between the congestion window and the throughput in the 100ms RTT test. After
some digging, it turns out that this happens because of a curious case of two
different scales accidentally lining up. Remember that the congestion window is
plotted as 10s of kilobytes, and thus we plot $c(x)$ as

\begin{align*}
  c(x) = cw_x \text{\ (B)}
       = \frac{cw_x}{1024} \text{\ (kB)}
       = \frac{cw_x}{10 \cdot 1024} \text{\ (10 kB)}
\end{align*}

now, consider the throughput $t'(cw)$ allowed by a congestion window of size
$cw$ over a link with RTT $\approx 100ms$:

\begin{align*}
  t'(cw) &= \frac{cw}{0.100}                       &&\text{(Bps)} \\
         &= \frac{cw}{0.100 \cdot 10 \cdot 1024}
          = \frac{cw}{1024}                        &&\text{(MBps)} \\
         &= \frac{cw}{8 \cdot 1024}                &&\text{(Mbps)}
\end{align*}

Since the congestion window is not allowed to grow to the bandwidth delay
product as explained above, we expect the real throughput $t(x)$ to be
approximately limited by $t'(cw_x)$. It is pretty clear from the above that
$t'(cw) = 0.8 c(x)$, and so in this particular setup, we would expect to
see the throughput follow the congestion window closely at these particular
scales because $t(x) \approx 0.8 c(x)$.

\subsection{What if pigs could fly?} % Optimal solution

\section{Conclusion}

%Subfig example
%\begin{figure}[h]
% \centering
% \subfloat[][cross-channel interference] {\
%   \scalebox{0.55}{\input{graphs/mp-int-2.4-ni.tex}}\label{graph:cc-interference}
% }
% \subfloat[][same-channel interference] {\
%   \scalebox{0.55}{\input{graphs/mp-int-2.4-i.tex}}\label{graph:sc-interference}
% }
%
% \caption{Interference experiments}\label{graph:interference}
%\end{figure}

\end{document}
% vim:textwidth=80:colorcolumn=80:
